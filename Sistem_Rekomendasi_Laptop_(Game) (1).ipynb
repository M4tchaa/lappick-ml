{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install Sastrawi\n",
        "!pip install fuzzywuzzy python-Levenshtein"
      ],
      "metadata": {
        "id": "kbBnO1KJWy8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ownot7oYBch"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "laptop_df = pd.read_csv('cleaned_dataset.csv')\n",
        "min_req_df = pd.read_csv('minimum_requirements_game.csv')\n",
        "rec_req_df = pd.read_csv('recommended_requirements_game.csv')\n",
        "cpu_bench_df = pd.read_csv('cpu_benchmarks.csv')\n",
        "gpu_bench_df = pd.read_csv('gpu_benchmarks.csv')\n",
        "\n",
        "# Lihat struktur kolom dan sampel data\n",
        "print(\"=== Laptop Dataset ===\")\n",
        "print(laptop_df.info())\n",
        "print(laptop_df.head())\n",
        "\n",
        "print(\"\\n=== Minimum Requirements ===\")\n",
        "print(min_req_df.info())\n",
        "print(min_req_df.head())\n",
        "\n",
        "print(\"\\n=== Recommended Requirements ===\")\n",
        "print(rec_req_df.info())\n",
        "print(rec_req_df.head())\n",
        "\n",
        "print(\"\\n=== CPU Benchmark ===\")\n",
        "print(cpu_bench_df.info())\n",
        "print(cpu_bench_df.head())\n",
        "\n",
        "print(\"\\n=== GPU Benchmark ===\")\n",
        "print(gpu_bench_df.info())\n",
        "print(gpu_bench_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKpvuiIgzPXR"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def split_cpu_vendor(cpu_string):\n",
        "    \"\"\"\n",
        "    Pisahkan CPU Intel dan AMD dari string CPU.\n",
        "    Return tuple: (intel_cpu, amd_cpu)\n",
        "    \"\"\"\n",
        "    if pd.isna(cpu_string):\n",
        "        return '', ''\n",
        "    # Pisahkan model (/, |, ,)\n",
        "    cpu_models = re.split(r'[\\/|,]', cpu_string)\n",
        "    cpu_models = [m.strip() for m in cpu_models if m.strip()]\n",
        "\n",
        "    intel_cpu = ''\n",
        "    amd_cpu = ''\n",
        "\n",
        "    for cpu in cpu_models:\n",
        "        if re.search(r'Intel|Pentium|Celeron|Core|Xeon', cpu, re.I):\n",
        "            intel_cpu = cpu if not intel_cpu else intel_cpu + ' / ' + cpu\n",
        "        elif re.search(r'AMD|Ryzen|FX|Athlon|Phenom|Opteron', cpu, re.I):\n",
        "            amd_cpu = cpu if not amd_cpu else amd_cpu + ' / ' + cpu\n",
        "    return intel_cpu, amd_cpu\n",
        "\n",
        "def split_gpu_vendor(gpu_string):\n",
        "    \"\"\"\n",
        "    Pisahkan GPU NVIDIA, AMD, dan Intel dari string GPU.\n",
        "    Return tuple: (nvidia_gpu, amd_gpu, intel_gpu)\n",
        "    \"\"\"\n",
        "    if pd.isna(gpu_string):\n",
        "        return '', '', ''\n",
        "    gpu_models = re.split(r'[\\/|,]', gpu_string)\n",
        "    gpu_models = [m.strip() for m in gpu_models if m.strip()]\n",
        "\n",
        "    nvidia_gpu = ''\n",
        "    amd_gpu = ''\n",
        "    intel_gpu = ''\n",
        "\n",
        "    for gpu in gpu_models:\n",
        "        if re.search(r'NVIDIA|GeForce', gpu, re.I):\n",
        "            nvidia_gpu = gpu if not nvidia_gpu else nvidia_gpu + ' / ' + gpu\n",
        "        elif re.search(r'AMD|Radeon', gpu, re.I):\n",
        "            amd_gpu = gpu if not amd_gpu else amd_gpu + ' / ' + gpu\n",
        "        elif re.search(r'Intel|Iris|UHD|HD Graphics', gpu, re.I):\n",
        "            intel_gpu = gpu if not intel_gpu else intel_gpu + ' / ' + gpu\n",
        "    return nvidia_gpu, amd_gpu, intel_gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMWO71txzykT"
      },
      "outputs": [],
      "source": [
        "# Pisahkan CPU\n",
        "cpu_split = rec_req_df['CPU'].apply(lambda x: pd.Series(split_cpu_vendor(x)))\n",
        "rec_req_df['CPU_Intel'] = cpu_split[0]\n",
        "rec_req_df['CPU_AMD'] = cpu_split[1]\n",
        "\n",
        "# Pisahkan GPU\n",
        "gpu_split = rec_req_df['GPU'].apply(lambda x: pd.Series(split_gpu_vendor(x)))\n",
        "rec_req_df['GPU_NVIDIA'] = gpu_split[0]\n",
        "rec_req_df['GPU_AMD'] = gpu_split[1]\n",
        "rec_req_df['GPU_Intel'] = gpu_split[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTo2ouh1286I"
      },
      "outputs": [],
      "source": [
        "# Pisahkan CPU\n",
        "cpu_split = min_req_df['CPU'].apply(lambda x: pd.Series(split_cpu_vendor(x)))\n",
        "min_req_df['CPU_Intel'] = cpu_split[0]\n",
        "min_req_df['CPU_AMD'] = cpu_split[1]\n",
        "\n",
        "# Pisahkan GPU\n",
        "gpu_split = min_req_df['GPU'].apply(lambda x: pd.Series(split_gpu_vendor(x)))\n",
        "min_req_df['GPU_NVIDIA'] = gpu_split[0]\n",
        "min_req_df['GPU_AMD'] = gpu_split[1]\n",
        "min_req_df['GPU_Intel'] = gpu_split[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9JIuMdJ-mpl"
      },
      "outputs": [],
      "source": [
        "# Drop kolom CPU dan GPU dari minimum requirements\n",
        "min_req_df = min_req_df.drop(columns=['CPU', 'GPU'])\n",
        "\n",
        "# Drop kolom CPU dan GPU dari recommended requirements\n",
        "rec_req_df = rec_req_df.drop(columns=['CPU', 'GPU'])\n",
        "\n",
        "print(\"Kolom CPU & GPU udah di-drop dari dataset minimum & recommended!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJDBsAFTy9Xf"
      },
      "outputs": [],
      "source": [
        "print(rec_req_df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyIZv32kAZzX"
      },
      "outputs": [],
      "source": [
        "print(min_req_df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1-whu6tzHFE"
      },
      "outputs": [],
      "source": [
        "# Ubah kolom Category jadi list\n",
        "min_req_df['Category'] = min_req_df['Category'].str.split(' / ')\n",
        "rec_req_df['Category'] = rec_req_df['Category'].str.split(' / ')\n",
        "\n",
        "print(\"Kolom 'Category' udah jadi list di kedua dataset!\")\n",
        "print(min_req_df[['Game', 'Category']].head())\n",
        "print(rec_req_df[['Game', 'Category']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDxIYXfpsXGP"
      },
      "outputs": [],
      "source": [
        "from fuzzywuzzy import process\n",
        "import pandas as pd\n",
        "\n",
        "# Buat dict lookup dari benchmark\n",
        "cpu_lookup = dict(zip(cpu_bench_df['CPU Model'], cpu_bench_df['CPU Score']))\n",
        "gpu_lookup = dict(zip(gpu_bench_df['GPU Model'], gpu_bench_df['GPU Score']))\n",
        "\n",
        "# Fungsi matching CPU\n",
        "def match_cpu_score(cpu_name):\n",
        "    if pd.isna(cpu_name) or cpu_name.strip() == '':\n",
        "        return 0\n",
        "    cpu_list = [c.strip() for c in cpu_name.split('/') if c.strip() != '']\n",
        "    scores = []\n",
        "    for cpu in cpu_list:\n",
        "        match = process.extractOne(cpu, cpu_lookup.keys(), score_cutoff=80)\n",
        "        if match:\n",
        "            scores.append(cpu_lookup[match[0]])\n",
        "    return max(scores, default=0)\n",
        "\n",
        "# Fungsi matching GPU\n",
        "def match_gpu_score(gpu_name):\n",
        "    if pd.isna(gpu_name) or gpu_name.strip() == '':\n",
        "        return 0\n",
        "    gpu_list = [g.strip() for g in gpu_name.split('/') if g.strip() != '']\n",
        "    scores = []\n",
        "    for gpu in gpu_list:\n",
        "        if 'Integrated' in gpu or gpu.lower() == 'integrated':\n",
        "            scores.append(300)\n",
        "        else:\n",
        "            match = process.extractOne(gpu, gpu_lookup.keys(), score_cutoff=80)\n",
        "            if match:\n",
        "                scores.append(gpu_lookup[match[0]])\n",
        "    return max(scores, default=0)\n",
        "\n",
        "# Fungsi isi nilai kosong dari kolom lain\n",
        "def fill_empty_with_other(row, col1, col2):\n",
        "    if pd.isna(row[col1]) or row[col1].strip() == '':\n",
        "        return row[col2]\n",
        "    if pd.isna(row[col2]) or row[col2].strip() == '':\n",
        "        return row[col1]\n",
        "    return row[col1]\n",
        "\n",
        "# Proses Minimum Requirements\n",
        "print(\"⚙️ Proses Minimum Requirements...\")\n",
        "\n",
        "# CPU\n",
        "min_req_df['CPU_AMD'] = min_req_df.apply(lambda row: fill_empty_with_other(row, 'CPU_AMD', 'CPU_Intel'), axis=1)\n",
        "min_req_df['CPU_Intel'] = min_req_df.apply(lambda row: fill_empty_with_other(row, 'CPU_Intel', 'CPU_AMD'), axis=1)\n",
        "\n",
        "# GPU - pastikan semua GPU terisi\n",
        "min_req_df['GPU_AMD'] = min_req_df.apply(lambda row: fill_empty_with_other(row, 'GPU_AMD', 'GPU_NVIDIA'), axis=1)\n",
        "min_req_df['GPU_NVIDIA'] = min_req_df.apply(lambda row: fill_empty_with_other(row, 'GPU_NVIDIA', 'GPU_AMD'), axis=1)\n",
        "min_req_df['GPU_Intel'] = min_req_df.apply(lambda row: fill_empty_with_other(row, 'GPU_Intel', 'GPU_NVIDIA'), axis=1)\n",
        "min_req_df['GPU_Intel'] = min_req_df.apply(lambda row: fill_empty_with_other(row, 'GPU_Intel', 'GPU_AMD'), axis=1)\n",
        "\n",
        "# Matching skor\n",
        "min_req_df['CPU_Intel_score'] = min_req_df['CPU_Intel'].apply(match_cpu_score)\n",
        "min_req_df['CPU_AMD_score'] = min_req_df['CPU_AMD'].apply(match_cpu_score)\n",
        "min_req_df['GPU_NVIDIA_score'] = min_req_df['GPU_NVIDIA'].apply(match_gpu_score)\n",
        "min_req_df['GPU_AMD_score'] = min_req_df['GPU_AMD'].apply(match_gpu_score)\n",
        "min_req_df['GPU_Intel_score'] = min_req_df['GPU_Intel'].apply(match_gpu_score)\n",
        "\n",
        "# Update GPU_NVIDIA_score & GPU_AMD_score kalau kosong, pakai GPU_Intel_score\n",
        "min_req_df.loc[min_req_df['GPU_NVIDIA_score'] == 0, 'GPU_NVIDIA_score'] = min_req_df['GPU_Intel_score']\n",
        "min_req_df.loc[min_req_df['GPU_AMD_score'] == 0, 'GPU_AMD_score'] = min_req_df['GPU_Intel_score']\n",
        "\n",
        "# Proses Recommended Requirements\n",
        "print(\"⚙️ Proses Recommended Requirements...\")\n",
        "\n",
        "# CPU\n",
        "rec_req_df['CPU_AMD'] = rec_req_df.apply(lambda row: fill_empty_with_other(row, 'CPU_AMD', 'CPU_Intel'), axis=1)\n",
        "rec_req_df['CPU_Intel'] = rec_req_df.apply(lambda row: fill_empty_with_other(row, 'CPU_Intel', 'CPU_AMD'), axis=1)\n",
        "\n",
        "# GPU\n",
        "rec_req_df['GPU_AMD'] = rec_req_df.apply(lambda row: fill_empty_with_other(row, 'GPU_AMD', 'GPU_NVIDIA'), axis=1)\n",
        "rec_req_df['GPU_NVIDIA'] = rec_req_df.apply(lambda row: fill_empty_with_other(row, 'GPU_NVIDIA', 'GPU_AMD'), axis=1)\n",
        "rec_req_df['GPU_Intel'] = rec_req_df.apply(lambda row: fill_empty_with_other(row, 'GPU_Intel', 'GPU_NVIDIA'), axis=1)\n",
        "rec_req_df['GPU_Intel'] = rec_req_df.apply(lambda row: fill_empty_with_other(row, 'GPU_Intel', 'GPU_AMD'), axis=1)\n",
        "\n",
        "# Matching skor\n",
        "rec_req_df['CPU_Intel_score'] = rec_req_df['CPU_Intel'].apply(match_cpu_score)\n",
        "rec_req_df['CPU_AMD_score'] = rec_req_df['CPU_AMD'].apply(match_cpu_score)\n",
        "rec_req_df['GPU_NVIDIA_score'] = rec_req_df['GPU_NVIDIA'].apply(match_gpu_score)\n",
        "rec_req_df['GPU_AMD_score'] = rec_req_df['GPU_AMD'].apply(match_gpu_score)\n",
        "rec_req_df['GPU_Intel_score'] = rec_req_df['GPU_Intel'].apply(match_gpu_score)\n",
        "\n",
        "# Update GPU_NVIDIA_score & GPU_AMD_score kalau kosong, pakai GPU_Intel_score\n",
        "rec_req_df.loc[rec_req_df['GPU_NVIDIA_score'] == 0, 'GPU_NVIDIA_score'] = rec_req_df['GPU_Intel_score']\n",
        "rec_req_df.loc[rec_req_df['GPU_AMD_score'] == 0, 'GPU_AMD_score'] = rec_req_df['GPU_Intel_score']\n",
        "\n",
        "# Cek hasil\n",
        "print(\"\\n=== Hasil Skor Minimum Requirements (FuzzyWuzzy) ===\")\n",
        "print(min_req_df[['Game', 'CPU_Intel', 'CPU_AMD', 'CPU_Intel_score', 'CPU_AMD_score',\n",
        "                   'GPU_NVIDIA', 'GPU_AMD', 'GPU_Intel',\n",
        "                   'GPU_NVIDIA_score', 'GPU_AMD_score', 'GPU_Intel_score']].head())\n",
        "\n",
        "print(\"\\n=== Hasil Skor Recommended Requirements (FuzzyWuzzy) ===\")\n",
        "print(rec_req_df[['Game', 'CPU_Intel', 'CPU_AMD', 'CPU_Intel_score', 'CPU_AMD_score',\n",
        "                   'GPU_NVIDIA', 'GPU_AMD', 'GPU_Intel',\n",
        "                   'GPU_NVIDIA_score', 'GPU_AMD_score', 'GPU_Intel_score']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37EVH0BA1s6n"
      },
      "outputs": [],
      "source": [
        "# Simpan rec_req_df ke CSV\n",
        "rec_req_df.to_csv('recommended_requirements_processed.csv', index=False)\n",
        "print(\"DataFrame 'rec_req_df' telah disimpan ke 'recommended_requirements_processed.csv'\")\n",
        "\n",
        "# Simpan min_req_df ke CSV\n",
        "min_req_df.to_csv('minimum_requirements_processed.csv', index=False)\n",
        "print(\"DataFrame 'min_req_df' telah disimpan ke 'minimum_requirements_processed.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nk5McpiQtreY"
      },
      "outputs": [],
      "source": [
        "from fuzzywuzzy import process\n",
        "import pandas as pd\n",
        "\n",
        "# Lookup dictionary\n",
        "cpu_lookup = dict(zip(cpu_bench_df['CPU Model'], cpu_bench_df['CPU Score']))\n",
        "gpu_lookup = dict(zip(gpu_bench_df['GPU Model'], gpu_bench_df['GPU Score']))\n",
        "\n",
        "# Fungsi matching CPU\n",
        "def match_cpu_score(cpu_name):\n",
        "    if pd.isna(cpu_name) or cpu_name.strip() == '':\n",
        "        return 0\n",
        "    match = process.extractOne(cpu_name, cpu_lookup.keys(), score_cutoff=80)\n",
        "    if match:\n",
        "        return cpu_lookup[match[0]]\n",
        "    return 0\n",
        "\n",
        "# Fungsi matching GPU\n",
        "def match_gpu_score(gpu_name):\n",
        "    if pd.isna(gpu_name) or gpu_name.strip() == '':\n",
        "        return 0\n",
        "    if 'Integrated' in gpu_name or gpu_name.lower() == 'integrated':\n",
        "        return 300\n",
        "    match = process.extractOne(gpu_name, gpu_lookup.keys(), score_cutoff=80)\n",
        "    if match:\n",
        "        return gpu_lookup[match[0]]\n",
        "    return 0\n",
        "\n",
        "# Proses pencarian skor untuk laptop_df\n",
        "laptop_df['CPU_score'] = laptop_df['CPU'].apply(match_cpu_score)\n",
        "laptop_df['GPU_score'] = laptop_df['GPU'].apply(match_gpu_score)\n",
        "\n",
        "# Hasil\n",
        "print(\"\\n=== Hasil Skor Dataset Laptop ===\")\n",
        "print(laptop_df[['Brand', 'Model', 'CPU', 'CPU_score', 'GPU', 'GPU_score', 'Final Price']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEpzO6Ug0F_v"
      },
      "outputs": [],
      "source": [
        "# Simpan laptop_df ke CSV\n",
        "laptop_df.to_csv('laptop_data_processed.csv', index=False)\n",
        "print(\"DataFrame 'laptop_df' telah disimpan ke 'laptop_data_processed.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dS-FgIl35Wq0"
      },
      "outputs": [],
      "source": [
        "def clean_ram(ram_str):\n",
        "    if pd.isna(ram_str) or ram_str.strip() == '' or ram_str.lower() == 'unknown':\n",
        "        return 0  # default ke 0 jika tidak diketahui\n",
        "\n",
        "    ram_str = str(ram_str).lower().strip()\n",
        "    if 'gb' in ram_str:\n",
        "        return int(float(ram_str.replace('gb', '').strip()))\n",
        "    elif 'mb' in ram_str:\n",
        "        mb_value = float(ram_str.replace('mb', '').strip())\n",
        "        return int(mb_value / 1024) if mb_value >= 512 else 1\n",
        "    else:\n",
        "        # fallback jika tidak ada satuan, tapi string bisa dikonversi\n",
        "        try:\n",
        "            return int(float(ram_str))\n",
        "        except ValueError:\n",
        "            return 0  # fallback jika tidak bisa dikonversi\n",
        "\n",
        "# Terapkan\n",
        "min_req_df['RAM'] = min_req_df['RAM'].apply(clean_ram)\n",
        "rec_req_df['RAM'] = rec_req_df['RAM'].apply(clean_ram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1CVyqcO9Drt"
      },
      "outputs": [],
      "source": [
        "def clean_file_size(size_str):\n",
        "    if pd.isna(size_str) or size_str.strip() == '' or size_str.lower() == 'unknown':\n",
        "        return 0\n",
        "\n",
        "    size_str = str(size_str).lower().strip()\n",
        "    if 'gb' in size_str:\n",
        "        return int(float(size_str.replace('gb', '').strip()))\n",
        "    elif 'mb' in size_str:\n",
        "        mb_value = float(size_str.replace('mb', '').strip())\n",
        "        return int(mb_value / 1024) if mb_value >= 512 else 1\n",
        "    else:\n",
        "        # fallback jika tidak ada satuan, tapi string bisa dikonversi\n",
        "        try:\n",
        "            return int(float(size_str))\n",
        "        except ValueError:\n",
        "            return 0\n",
        "\n",
        "# Terapkan\n",
        "min_req_df['File Size'] = min_req_df['File Size'].apply(clean_file_size)\n",
        "rec_req_df['File Size'] = rec_req_df['File Size'].apply(clean_file_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63H0Q_sA3zE_"
      },
      "outputs": [],
      "source": [
        "def categorize_laptops(game_name, df_min, df_rec, df_laptops, ram_weight=1.0, storage_weight=1.0):\n",
        "    game_req = df_min[df_min['Game'].str.lower() == game_name.lower()]\n",
        "    game_rec = df_rec[df_rec['Game'].str.lower() == game_name.lower()]\n",
        "    if game_req.empty or game_rec.empty:\n",
        "        print(f\"Game '{game_name}' tidak ditemukan.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    req_row_min = game_req.iloc[0]\n",
        "    req_row_rec = game_rec.iloc[0]\n",
        "\n",
        "    ram_req = req_row_min['RAM']\n",
        "    storage_req = req_row_min['File Size']\n",
        "\n",
        "    # --- Vendor detection helper ---\n",
        "    def get_gpu_vendor(gpu_name):\n",
        "        gpu_name = gpu_name.lower()\n",
        "        if any(x in gpu_name for x in ['rtx', 'gtx', 'mx']):\n",
        "            return 'nvidia'\n",
        "        elif any(x in gpu_name for x in ['radeon', 'rx', 'vega', 'pro']):\n",
        "            return 'amd'\n",
        "        elif any(x in gpu_name for x in ['integrated', 'iris', 'uhd']):\n",
        "            return 'intel'\n",
        "        else:\n",
        "            return 'intel'  # fallback\n",
        "\n",
        "    # --- CPU detection helper ---\n",
        "    def get_cpu_vendor(cpu_name):\n",
        "        cpu_name = cpu_name.lower()\n",
        "        if 'intel' in cpu_name:\n",
        "            return 'intel'\n",
        "        elif 'amd' in cpu_name:\n",
        "            return 'amd'\n",
        "        else:\n",
        "            return 'intel'  # fallback\n",
        "\n",
        "    # --- Ambil score ---\n",
        "    def get_cpu_score(row, req_row):\n",
        "        vendor = get_cpu_vendor(row['CPU'])\n",
        "        if vendor == 'intel':\n",
        "            return req_row['CPU_Intel_score']\n",
        "        elif vendor == 'amd':\n",
        "            return req_row['CPU_AMD_score']\n",
        "        else:\n",
        "            return req_row['CPU_Intel_score']\n",
        "\n",
        "    def get_gpu_score(row, req_row):\n",
        "        vendor = get_gpu_vendor(row['GPU'])\n",
        "        if vendor == 'nvidia':\n",
        "            return req_row['GPU_NVIDIA_score']\n",
        "        elif vendor == 'amd':\n",
        "            return req_row['GPU_AMD_score']\n",
        "        elif vendor == 'intel':\n",
        "            return req_row['GPU_Intel_score']\n",
        "        else:\n",
        "            return req_row['GPU_Intel_score']\n",
        "\n",
        "    # --- Hitung match score ---\n",
        "    def calculate_match(row):\n",
        "        cpu_req = get_cpu_score(row, req_row_min)\n",
        "        gpu_req = get_gpu_score(row, req_row_min)\n",
        "        cpu_score = row['CPU_score'] / cpu_req if cpu_req > 0 else 1.0\n",
        "        gpu_score = row['GPU_score'] / gpu_req if gpu_req > 0 else 1.0\n",
        "        ram_score = (row['RAM'] / ram_req) * ram_weight if ram_req > 0 else 1.0\n",
        "        storage_score = (row['Storage'] / storage_req) * storage_weight if storage_req > 0 else 1.0\n",
        "        final_score = (cpu_score + gpu_score + ram_score + storage_score) / (2 + ram_weight + storage_weight)\n",
        "        return final_score\n",
        "\n",
        "    # --- Kategorisasi ---\n",
        "    def categorize(row):\n",
        "        cpu_min = get_cpu_score(row, req_row_min)\n",
        "        gpu_min = get_gpu_score(row, req_row_min)\n",
        "        cpu_rec = get_cpu_score(row, req_row_rec)\n",
        "        gpu_rec = get_gpu_score(row, req_row_rec)\n",
        "\n",
        "        if row['CPU_score'] < cpu_min or row['GPU_score'] < gpu_min:\n",
        "            return 'Disqualified'\n",
        "\n",
        "        cpu_rec_flag = row['CPU_score'] >= cpu_rec\n",
        "        gpu_rec_flag = row['GPU_score'] >= gpu_rec\n",
        "\n",
        "        if cpu_rec_flag and gpu_rec_flag:\n",
        "            return 'Recommended'\n",
        "        elif cpu_rec_flag or gpu_rec_flag:\n",
        "            return 'Mixed'\n",
        "        else:\n",
        "            return 'Minimum'\n",
        "\n",
        "    # --- Filter RAM & Storage ---\n",
        "    df_filtered = df_laptops[\n",
        "        (df_laptops['RAM'] >= ram_req) & (df_laptops['Storage'] >= storage_req)\n",
        "    ].copy()\n",
        "\n",
        "    # --- Hitung Match_Score ---\n",
        "    df_filtered['Match_Score'] = df_filtered.apply(calculate_match, axis=1)\n",
        "\n",
        "    # --- Tentukan Kategori ---\n",
        "    df_filtered['Category'] = df_filtered.apply(categorize, axis=1)\n",
        "\n",
        "    # --- Buang yang Disqualified ---\n",
        "    df_final = df_filtered[df_filtered['Category'] != 'Disqualified'].copy()\n",
        "\n",
        "    # --- Urutkan ---\n",
        "    df_final = df_final.sort_values(by='Match_Score', ascending=False).reset_index(drop=True)\n",
        "    return df_final\n",
        "\n",
        "# Contoh pemanggilan\n",
        "final_laptops = categorize_laptops('Genshin Impact', min_req_df, rec_req_df, laptop_df)\n",
        "print(final_laptops[['Brand', 'Model', 'CPU', 'GPU', 'RAM', 'Storage', 'Category', 'Match_Score']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XNarWwor2Em"
      },
      "outputs": [],
      "source": [
        "# Simpan DataFrame final_laptops ke CSV\n",
        "final_laptops.to_csv('final_laptops_categorized.csv', index=False)\n",
        "print(\"DataFrame 'final_laptops' telah disimpan ke 'final_laptops_categorized.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# --- 2. Cleaning kolom 'Description' ---\n",
        "def clean_description(desc):\n",
        "    \"\"\"\n",
        "    Bersihin newline, tanda kutip, spasi dobel, dan karakter aneh\n",
        "    \"\"\"\n",
        "    if pd.isnull(desc):\n",
        "        return \"\"\n",
        "    # newline -> spasi\n",
        "    desc = re.sub(r'\\n', ' ', desc)\n",
        "    # hapus tanda kutip\n",
        "    desc = re.sub(r'[\"\\']', '', desc)\n",
        "    # hapus karakter aneh (non-ASCII)\n",
        "    desc = re.sub(r'[^\\x00-\\x7F]+', ' ', desc)\n",
        "    # hapus spasi dobel\n",
        "    desc = re.sub(r'\\s+', ' ', desc)\n",
        "    return desc.strip()\n",
        "\n",
        "rec_req_df['Description'] = rec_req_df['Description'].apply(clean_description)\n",
        "min_req_df['Description'] = min_req_df['Description'].apply(clean_description)\n",
        "\n",
        "# --- 4. Cek hasil cleaning ---\n",
        "print(rec_req_df.head())\n",
        "print(min_req_df.head())\n",
        "\n",
        "# --- 5. Simpan dataset hasil cleaning (opsional) ---\n",
        "rec_req_df.to_csv('recommended_clean.csv', index=False)\n",
        "min_req_df.to_csv('minimum_clean.csv', index=False)\n",
        "\n",
        "print(\"✅ Preprocessing selesai. Dataset lebih rapi!\")"
      ],
      "metadata": {
        "id": "YCL5iZpMmz9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Knowledge Base 1: mapping game → minimum/recommended requirement\n",
        "\n",
        "# Buat dictionary mapping game ke requirement\n",
        "min_req_kb = min_req_df.set_index('Game').to_dict('index')\n",
        "rec_req_kb = rec_req_df.set_index('Game').to_dict('index')\n",
        "\n",
        "# Contoh akses\n",
        "game_name = 'Assassin\\'s Creed Shadows'\n",
        "print(\"Minimum Requirement:\", min_req_kb.get(game_name, {}))\n",
        "print(\"Recommended Requirement:\", rec_req_kb.get(game_name, {}))"
      ],
      "metadata": {
        "id": "BFKZXCQQ3K-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Knowledge Base 2: mapping laptop → CPU, GPU, RAM score, and Brand\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "# Create a dictionary mapping laptop Model to a list of specs (including Brand)\n",
        "# Using defaultdict(list) allows easily appending specs for multiple configurations\n",
        "# of the same model.\n",
        "laptop_kb = defaultdict(list)\n",
        "\n",
        "for _, row in laptop_df.iterrows():\n",
        "    model = row['Model']\n",
        "    specs = {\n",
        "        'Brand': row['Brand'], # Add Brand here\n",
        "        'CPU_score': row['CPU_score'],\n",
        "        'GPU_score': row['GPU_score'],\n",
        "        'RAM': row['RAM'],\n",
        "        'Final Price': row['Final Price'], # Add Final Price as well, it might be useful\n",
        "        'Storage': row['Storage'], # Add Storage\n",
        "        'Storage type': row['Storage type'] # Add Storage type\n",
        "    }\n",
        "    laptop_kb[model].append(specs)\n",
        "\n",
        "# Contoh akses\n",
        "laptop_name = 'ROG'\n",
        "print(\"Laptop Specs for\", laptop_name, \":\", laptop_kb.get(laptop_name, {}))\n",
        "\n",
        "# Contoh akses untuk melihat brand\n",
        "if laptop_kb.get(laptop_name):\n",
        "    print(\"Example Brand for\", laptop_name, \":\", laptop_kb[laptop_name][0].get('Brand'))\n",
        "\n",
        "# Example access for a different model\n",
        "laptop_name_2 = 'Katana' # Replace with another model from your data\n",
        "print(\"\\nLaptop Specs for\", laptop_name_2, \":\", laptop_kb.get(laptop_name_2, {}))"
      ],
      "metadata": {
        "id": "YLxPAcz13Ql9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_kb = {}\n",
        "\n",
        "# Loop semua game dan ambil categorynya\n",
        "for idx, row in min_req_df.iterrows():\n",
        "    categories = row['Category']\n",
        "    if isinstance(categories, list):  # sudah list\n",
        "        for cat in categories:\n",
        "            cat_lower = cat.lower().strip()\n",
        "            if cat_lower not in category_kb:\n",
        "                category_kb[cat_lower] = set()\n",
        "            category_kb[cat_lower].add(row['Game'])\n",
        "\n",
        "# Contoh akses\n",
        "print(\"Games in 'racing':\", category_kb.get('racing', set()))\n",
        "print(\"Games in 'racing':\", category_kb.get('balapan', set()))"
      ],
      "metadata": {
        "id": "VyfX0queriG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "\n",
        "# Ambil deskripsi game\n",
        "descriptions = min_req_df['Description'].fillna('').tolist()\n",
        "\n",
        "# Inisialisasi model multilingual\n",
        "# 'paraphrase-multilingual-MiniLM-L12-v2' adalah model multilingual yang cukup baik\n",
        "# yang dilatih di banyak pasangan bahasa.\n",
        "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "# Buat embeddings\n",
        "description_embeddings = model.encode(descriptions, convert_to_tensor=True)\n",
        "\n",
        "print(\"Shape embeddings:\", description_embeddings.shape)"
      ],
      "metadata": {
        "id": "hAJ5rCc65v9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc25c6f4"
      },
      "source": [
        "# Re-run the search_games cell to test with the new multilingual model\n",
        "import torch\n",
        "\n",
        "def search_games(query, model, description_embeddings, df, top_n=5, category_kb=None, category_boost=0.1):\n",
        "    # Encode query\n",
        "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "\n",
        "    # Hitung cosine similarity awal\n",
        "    similarities = torch.nn.functional.cosine_similarity(query_embedding, description_embeddings)\n",
        "\n",
        "    # Preprocess query untuk category matching\n",
        "    query_tokens_cleaned = basic_preprocessing(query)\n",
        "    query_tokens_cleaned = remove_stopwords(query_tokens_cleaned)\n",
        "    query_tokens_cleaned = map_synonyms(query_tokens_cleaned)\n",
        "\n",
        "    # Beri bobot berdasarkan kategori yang cocok\n",
        "    boosted_similarities = similarities.clone() # Salin skor kesamaan awal\n",
        "    for i in range(len(df)):\n",
        "        game_categories = df.iloc[i][\"Category\"]\n",
        "        if isinstance(game_categories, list):\n",
        "            # Check if any cleaned query token matches any category of the game\n",
        "            # Using a set for faster lookups\n",
        "            game_categories_lower = set([cat.lower() for cat in game_categories])\n",
        "            if any(token in game_categories_lower for token in query_tokens_cleaned):\n",
        "                boosted_similarities[i] += category_boost # Tambahkan bobot jika ada kecocokan kategori\n",
        "\n",
        "    # Urutkan berdasarkan boosted similarities\n",
        "    top_indices = boosted_similarities.argsort(descending=True)[:top_n]\n",
        "\n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        idx = idx.item()  # Convert tensor to int!\n",
        "        results.append({\n",
        "            \"game\": df.iloc[idx][\"Game\"],\n",
        "            \"category\": df.iloc[idx][\"Category\"],\n",
        "            \"similarity\": boosted_similarities[idx].item() # Gunakan skor yang sudah diberi bobot\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Contoh penggunaan dengan bobot kategori\n",
        "query = \"game balapan\"\n",
        "results = search_games(query, model, description_embeddings, min_req_df, top_n=10, category_boost=0.4) # Naikan bobot sedikit\n",
        "\n",
        "print(\"Hasil pencarian (dengan bobot kategori):\")\n",
        "for res in results:\n",
        "    print(res)\n",
        "\n",
        "query_2 = \"laptop buat game petualangan dunia terbuka\"\n",
        "results_2 = search_games(query_2, model, description_embeddings, min_req_df, top_n=10, category_boost=0.2)\n",
        "\n",
        "print(\"\\nHasil pencarian untuk 'laptop buat game petualangan dunia terbuka' (dengan bobot kategori):\")\n",
        "for res in results_2:\n",
        "    print(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from fuzzywuzzy import process # Import process\n",
        "from collections import defaultdict # Import defaultdict\n",
        "\n",
        "# ✅ Gunakan tokenizer berbasis regex untuk menghindari dependency resource spesifik\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "# Inisialisasi stopword remover Sastrawi\n",
        "factory = StopWordRemoverFactory()\n",
        "stopwords_sastrawi = set(factory.get_stop_words())\n",
        "\n",
        "# Tambahkan beberapa stopwords umum yang mungkin muncul di query rekomendasi\n",
        "additional_stopwords = {'cocok', 'buat', 'main', 'dengan', 'rekomendasi', 'spesifikasi', 'spek', 'apa', 'yang', 'game'}\n",
        "stopwords_sastrawi.update(additional_stopwords)\n",
        "\n",
        "# === 2️⃣ Stopword Removal ===\n",
        "def remove_stopwords(tokens):\n",
        "    return [t for t in tokens if t not in stopwords_sastrawi]\n",
        "\n",
        "# === 1️⃣ Basic Preprocessing ===\n",
        "def basic_preprocessing(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(f\"[{string.punctuation}’‘]\", \" \", text)  # tambah karakter khusus\n",
        "    tokens = tokenizer.tokenize(text)  # tokenizer regex\n",
        "    return tokens\n",
        "\n",
        "# === Create Keyword to Game Mapping (with uniqueness check) ===\n",
        "def create_keyword_game_map(game_list, stopwords):\n",
        "    keyword_candidate_map = defaultdict(list)\n",
        "    # First pass: collect all games for each keyword\n",
        "    for game in game_list:\n",
        "        tokens = basic_preprocessing(game)\n",
        "        tokens = remove_stopwords(tokens)\n",
        "        for token in tokens:\n",
        "            if len(token) > 2: # Only consider keywords longer than 2 characters\n",
        "                keyword_candidate_map[token].append(game)\n",
        "\n",
        "    # Second pass: identify unique keywords\n",
        "    unique_keyword_map = {}\n",
        "    for keyword, games in keyword_candidate_map.items():\n",
        "        if len(games) == 1: # If the keyword is associated with only one game\n",
        "            unique_keyword_map[keyword] = games[0] # Map keyword to the single game title\n",
        "\n",
        "    return unique_keyword_map # Return map of unique keywords to single game titles\n",
        "\n",
        "\n",
        "game_list = min_req_df['Game'].tolist()\n",
        "# Create the keyword map for games\n",
        "unique_keyword_game_map = create_keyword_game_map(game_list, stopwords_sastrawi)\n",
        "\n",
        "# === 3️⃣ Named Entity Recognition & Budget Extraction ===\n",
        "def extract_entities_and_budget(user_query, game_list, laptop_list, laptop_brand_list, unique_keyword_game_map, score_cutoff_high=95, score_cutoff_low_game=70, score_cutoff_low_laptop=80):\n",
        "    found_games = set()\n",
        "    found_laptops = set() # This will now include both models and brands\n",
        "    extracted_budget = None\n",
        "\n",
        "    query_lower = user_query.lower()\n",
        "    query_tokens = basic_preprocessing(user_query) # Tokenize query\n",
        "    query_tokens_cleaned = remove_stopwords(query_tokens) # Remove stopwords from query\n",
        "\n",
        "    # Reconstruct the cleaned query string for fuzzy matching\n",
        "    cleaned_query_string = \" \".join(query_tokens_cleaned)\n",
        "\n",
        "    # --- Extract Budget ---\n",
        "    # Look for patterns like \"10 juta\", \"15jt\", \"500 ribu\", \"rp 20000000\", or standalone large numbers\n",
        "    # Updated regex to also look for numbers with at least 6 digits, possibly preceded by 'budget' or 'harga'\n",
        "    budget_match = re.search(r'(\\d+)\\s*(juta|jt|ribu|rb|k)|rp\\s*(\\d+)|(?:budget|harga)\\s*(\\d{6,})|(\\d{6,})', query_lower)\n",
        "\n",
        "    if budget_match:\n",
        "        # Prioritize patterns with units or 'rp'\n",
        "        if budget_match.group(1): # Patterns with units\n",
        "            value_str = budget_match.group(1)\n",
        "            unit = budget_match.group(2)\n",
        "            try:\n",
        "                value = int(value_str)\n",
        "                if unit in ['juta', 'jt']:\n",
        "                    extracted_budget = value * 1_000_000\n",
        "                elif unit in ['ribu', 'rb', 'k']:\n",
        "                     extracted_budget = value * 1_000\n",
        "            except ValueError:\n",
        "                extracted_budget = None # Invalid number format\n",
        "        elif budget_match.group(3): # 'rp 12345' pattern\n",
        "            value_str = budget_match.group(3)\n",
        "            try:\n",
        "                extracted_budget = int(value_str)\n",
        "            except ValueError:\n",
        "                extracted_budget = None # Invalid number format\n",
        "        elif budget_match.group(4): # (?:budget|harga)\\s*(\\d{6,}) pattern\n",
        "             value_str = budget_match.group(4)\n",
        "             try:\n",
        "                 extracted_budget = int(value_str)\n",
        "             except ValueError:\n",
        "                 extracted_budget = None # Invalid number format\n",
        "        elif budget_match.group(5): # (\\d{6,}) standalone large number\n",
        "            value_str = budget_match.group(5)\n",
        "            try:\n",
        "                extracted_budget = int(value_str)\n",
        "            except ValueError:\n",
        "                extracted_budget = None # Invalid number format\n",
        "\n",
        "\n",
        "    # --- 3a: Unique Keyword Matching for Games (Prioritized) ---\n",
        "    unique_game_found = False\n",
        "    for token in query_tokens_cleaned:\n",
        "        if token in unique_keyword_game_map:\n",
        "            found_games.add(unique_keyword_game_map[token])\n",
        "            unique_game_found = True\n",
        "            break # Prioritize the first unique keyword found and stop game search\n",
        "\n",
        "    # --- 3b: Fuzzy Matching for Games (Only if no unique keyword found) ---\n",
        "    if not unique_game_found:\n",
        "        matches_games = process.extract(cleaned_query_string, game_list, limit=15)\n",
        "        for match, score in matches_games:\n",
        "            if score >= score_cutoff_low_game and match[0] in game_list and len(match[0]) > 1:\n",
        "                 if re.search(re.escape(match[0].lower()), cleaned_query_string):\n",
        "                      found_games.add(match[0])\n",
        "\n",
        "    # --- 3c: Token Containment Fallback for Games (If no games found yet) ---\n",
        "    if not found_games:\n",
        "        for token in query_tokens_cleaned:\n",
        "            if len(token) > 2:\n",
        "                 for game in game_list:\n",
        "                      if re.search(r'\\b' + re.escape(token) + r'\\b', game.lower()):\n",
        "                           found_games.add(game)\n",
        "\n",
        "    # --- 3d: Exact/High-Confidence Fuzzy Matching for Laptops (Models and Brands) ---\n",
        "    # Combine laptop models and brands for matching\n",
        "    laptop_entities = set(laptop_list + laptop_brand_list)\n",
        "\n",
        "    for entity in laptop_entities:\n",
        "         # Check for exact match first\n",
        "         if entity.lower() in cleaned_query_string:\n",
        "              found_laptops.add(entity)\n",
        "              continue # Move to next entity if exact match found\n",
        "\n",
        "         match = process.extractOne(entity, [cleaned_query_string], score_cutoff=score_cutoff_high)\n",
        "         if match:\n",
        "             found_laptops.add(match[0])\n",
        "\n",
        "    # --- 3e: Corrected Lower Cutoff Fuzzy Matching for Laptops (Fallback if no high-confidence found) ---\n",
        "    if not found_laptops:\n",
        "        # Iterate through combined laptop entities and match each against the cleaned query string\n",
        "        for entity in laptop_entities:\n",
        "            match = process.extractOne(entity, [cleaned_query_string], score_cutoff=score_cutoff_low_laptop)\n",
        "            if match:\n",
        "                # Check if the matched entity name (from the list) is present in the cleaned query string\n",
        "                if re.search(re.escape(entity.lower()), cleaned_query_string):\n",
        "                    found_laptops.add(entity)\n",
        "\n",
        "    return list(found_games), list(found_laptops), extracted_budget\n",
        "\n",
        "# === 4️⃣ Synonym Mapping ===\n",
        "SYNONYM_MAPPING = {\n",
        "    # Action\n",
        "    \"aksi\": \"action\",\n",
        "    \"laga\": \"action\",\n",
        "    \"action\": \"action\",\n",
        "\n",
        "    # Adventure\n",
        "    \"petualangan\": \"adventure\",\n",
        "    \"openworld\": \"adventure\",\n",
        "    \"open-world\": \"adventure\",\n",
        "    \"adventure\": \"adventure\",\n",
        "\n",
        "    # Animation & Modeling\n",
        "    \"animasi\": \"animation & modeling\",\n",
        "    \"modeling\": \"animation & modeling\",\n",
        "    \"animasi 3d\": \"animation & modeling\",\n",
        "\n",
        "    # Casual\n",
        "    \"santai\": \"casual\",\n",
        "    \"kasual\": \"casual\",\n",
        "    \"casual\": \"casual\",\n",
        "\n",
        "    # Design & Illustration\n",
        "    \"desain\": \"design & illustration\",\n",
        "    \"ilustrasi\": \"design & illustration\",\n",
        "    \"gambar\": \"design & illustration\",\n",
        "\n",
        "    # Early Access\n",
        "    \"akses awal\": \"early access\",\n",
        "    \"pre-release\": \"early access\",\n",
        "\n",
        "    # FPS\n",
        "    \"tembak\": \"fps\",\n",
        "    \"tembak-tembakan\": \"fps\",\n",
        "    \"first person\": \"fps\",\n",
        "    \"fps\": \"fps\",\n",
        "\n",
        "    # Fighting\n",
        "    \"pertarungan\": \"fighting\",\n",
        "    \"fighter\": \"fighting\",\n",
        "    \"bela diri\": \"fighting\",\n",
        "\n",
        "    # Free to Play\n",
        "    \"gratis\": \"free to play\",\n",
        "    \"f2p\": \"free to play\",\n",
        "    \"free\": \"free to play\",\n",
        "\n",
        "    # Game Development\n",
        "    \"pengembangan game\": \"game development\",\n",
        "    \"dev game\": \"game development\",\n",
        "    \"pembuatan game\": \"game development\",\n",
        "\n",
        "    # Gore\n",
        "    \"kekerasan grafis\": \"gore\",\n",
        "    \"darah\": \"gore\",\n",
        "    \"gore\": \"gore\",\n",
        "\n",
        "    # Indie\n",
        "    \"indie\": \"indie\",\n",
        "    \"independen\": \"indie\",\n",
        "    \"permainan indie\": \"indie\",\n",
        "\n",
        "    # JRPG\n",
        "    \"rpg jepang\": \"jrpg\",\n",
        "    \"jrpg\": \"jrpg\",\n",
        "    \"anime rpg\": \"jrpg\",\n",
        "\n",
        "    # MMO\n",
        "    \"mmo\": \"mmo\",\n",
        "    \"multiplayer masif\": \"mmo\",\n",
        "    \"game online\": \"mmo\",\n",
        "\n",
        "    # MOBA\n",
        "    \"moba\": \"moba\",\n",
        "    \"arena battle\": \"moba\",\n",
        "    \"dota-like\": \"moba\",\n",
        "\n",
        "    # Photo Editing\n",
        "    \"edit foto\": \"photo editing\",\n",
        "    \"foto\": \"photo editing\",\n",
        "    \"photoshop\": \"photo editing\",\n",
        "\n",
        "    # Platformer\n",
        "    \"platform\": \"platformer\",\n",
        "    \"lompat\": \"platformer\",\n",
        "    \"arcade\": \"platformer\",\n",
        "\n",
        "    # RPG\n",
        "    \"role playing\": \"rpg\",\n",
        "    \"rpg\": \"rpg\",\n",
        "    \"peran\": \"rpg\",\n",
        "\n",
        "    # Racing\n",
        "    \"balapan\": \"racing\",\n",
        "    \"balap\": \"racing\",\n",
        "    \"racing\": \"racing\",\n",
        "\n",
        "    # Rogue-like\n",
        "    \"roguelike\": \"rogue-like\",\n",
        "    \"permadeath\": \"rogue-like\",\n",
        "    \"prosedural\": \"rogue-like\",\n",
        "\n",
        "    # Sexual Content\n",
        "    \"konten dewasa\": \"sexual content\",\n",
        "    \"seksual\": \"sexual content\",\n",
        "    \"dewasa\": \"sexual content\",\n",
        "\n",
        "    # Simulation\n",
        "    \"simulasi\": \"simulation\",\n",
        "    \"sim\": \"simulation\",\n",
        "    \"simulator\": \"simulation\",\n",
        "\n",
        "    # Space\n",
        "    \"angkasa\": \"space\",\n",
        "    \"luar angkasa\": \"space\",\n",
        "    \"space\": \"space\",\n",
        "\n",
        "    # Sports\n",
        "    \"olahraga\": \"sports\",\n",
        "    \"sport\": \"sports\",\n",
        "    \"olahraga elektronik\": \"sports\",\n",
        "\n",
        "    # Strategy\n",
        "    \"strategi\": \"strategy\",\n",
        "    \"strategic\": \"strategy\",\n",
        "    \"taktik\": \"strategy\",\n",
        "\n",
        "    # Third-person shooter\n",
        "    \"tps\": \"third-person shooter\",\n",
        "    \"shooter orang ketiga\": \"third-person shooter\",\n",
        "    \"third person\": \"third-person shooter\",\n",
        "\n",
        "    # Turn-based\n",
        "    \"giliran\": \"turn-based\",\n",
        "    \"turn based\": \"turn-based\",\n",
        "    \"tb\": \"turn-based\",\n",
        "\n",
        "    # Unknown\n",
        "    \"tidak diketahui\": \"unknown\",\n",
        "    \"unknown\": \"unknown\",\n",
        "    \"misteri\": \"unknown\",\n",
        "\n",
        "    # Utilities\n",
        "    \"alat\": \"utilities\",\n",
        "    \"tool\": \"utilities\",\n",
        "    \"utilitas\": \"utilities\",\n",
        "\n",
        "    # Video Production\n",
        "    \"produksi video\": \"video production\",\n",
        "    \"editing video\": \"video production\",\n",
        "    \"video editor\": \"video production\",\n",
        "\n",
        "    # Violent\n",
        "    \"kekerasan\": \"violent\",\n",
        "    \"violent\": \"violent\",\n",
        "    \"brutal\": \"violent\"\n",
        "}\n",
        "\n",
        "def map_synonyms(tokens):\n",
        "    return [SYNONYM_MAPPING.get(t, t) for t in tokens]\n",
        "\n",
        "# === Update Pipeline Function ===\n",
        "def nlp_pipeline_fuzzy(user_query, game_list, laptop_list, laptop_brand_list, unique_keyword_game_map):\n",
        "    tokens = basic_preprocessing(user_query)\n",
        "    tokens = remove_stopwords(tokens)\n",
        "    tokens = map_synonyms(tokens)\n",
        "    # Use the improved entity extraction and budget extraction function, passing brand list\n",
        "    found_games, found_laptops, extracted_budget = extract_entities_and_budget(user_query, game_list, laptop_list, laptop_brand_list, unique_keyword_game_map)\n",
        "\n",
        "    return {\n",
        "        \"tokens\": tokens,\n",
        "        \"found_games\": found_games,\n",
        "        \"found_laptops\": found_laptops, # This now includes both models and brands\n",
        "        \"budget\": extracted_budget\n",
        "    }\n",
        "\n",
        "# === Contoh penggunaan dengan fuzzy matching ===\n",
        "game_list = min_req_df['Game'].tolist()\n",
        "laptop_list = laptop_df['Model'].tolist()\n",
        "# Get the list of unique laptop brands\n",
        "laptop_brand_list = laptop_df['Brand'].unique().tolist()\n",
        "\n",
        "unique_keyword_game_map = create_keyword_game_map(game_list, stopwords_sastrawi) # Create the unique keyword map\n",
        "\n",
        "# Test cases\n",
        "queries = [\n",
        "    \"Laptop yang cocok buat main assasin creed apa dengan laptop ASUS?\",\n",
        "    \"Laptop yang cocok buat main Genshin apa dengan laptop Katana?\",\n",
        "    \"Laptop yang cocok buat main Honkai apa dengan laptop Voom?\",\n",
        "    \"Rekomendasi Laptop yang cocok buat main Honkai apa dengan laptop V15?\",\n",
        "    \"Spek laptop TUF buat game Valorant\",\n",
        "    \"Laptop yang cocok buat main assasin creed odyssey apa dengan laptop ROG?\",\n",
        "    \"Laptop msi buat game assassin\",\n",
        "    \"Rekomendasi laptop Omen untuk Genshin Impact dengan budget 20 juta\",\n",
        "    \"Cari laptop untuk game balapan dengan budget 15jt\",\n",
        "    \"Saya butuh laptop untuk main Game Pass dibawah 10 ribu rupiah\",\n",
        "    \"Laptop gaming seharga 500 ribu\",\n",
        "    \"Budget saya 30000000 untuk laptop gaming\",\n",
        "    \"Laptop Asus untuk game Valorant\",\n",
        "    \"Cari laptop Acer buat game balapan\",\n",
        "    \"Butuh laptop HP budget 10 juta\"\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "    # Pass the brand list to the pipeline\n",
        "    result = nlp_pipeline_fuzzy(query, game_list, laptop_list, laptop_brand_list, unique_keyword_game_map)\n",
        "    print(f\"\\nQuery: {query}\\nResult: {result}\")"
      ],
      "metadata": {
        "id": "uWt71Hh3_cpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7a0fe97"
      },
      "source": [
        "import pandas as pd\n",
        "import torch # Import torch for semantic search\n",
        "from fuzzywuzzy import process # Import process for fuzzy matching\n",
        "\n",
        "# --- Fungsi Rekomendasi Utama ---\n",
        "def get_laptop_recommendations(user_query, laptop_df, min_req_df, rec_req_df,\n",
        "                               min_req_kb, rec_req_kb,\n",
        "                               model, description_embeddings,\n",
        "                               laptop_list, laptop_brand_list, unique_keyword_game_map,\n",
        "                               category_boost_value=0.2, # Bobot kategori untuk semantic search\n",
        "                               top_n_semantic_games=5 # Jumlah game teratas dari semantic search jika tidak ada game spesifik\n",
        "                               ):\n",
        "\n",
        "    print(f\"Query Pengguna: {user_query}\")\n",
        "\n",
        "    # 1. Jalankan NLP Pipeline\n",
        "    pipeline_result = nlp_pipeline_fuzzy(user_query, min_req_df['Game'].tolist(), laptop_df['Model'].tolist(), laptop_df['Brand'].unique().tolist(), unique_keyword_game_map)\n",
        "    found_games = pipeline_result['found_games']\n",
        "    found_laptops_entities = pipeline_result['found_laptops'] # Bisa berisi brand atau model\n",
        "    extracted_budget = pipeline_result['budget']\n",
        "\n",
        "    print(f\"Hasil NLP Pipeline: Game Terdeteksi={found_games}, Laptop Terdeteksi={found_laptops_entities}, Budget Terdeteksi={extracted_budget}\")\n",
        "\n",
        "    # --- Tambahkan logika pengecekan game terdeteksi ---\n",
        "    if not found_games:\n",
        "        print(\"Tidak ada game spesifik terdeteksi dari query.\")\n",
        "        # Cek apakah hanya ada budget dan/atau laptop spesifik\n",
        "        if found_laptops_entities or extracted_budget is not None and extracted_budget > 0:\n",
        "             # Jika ada info laptop/budget tapi tidak ada game, tanya pengguna\n",
        "             return pd.DataFrame({\"Status\": [\"Butuh Info Game\"], \"Pesan\": [\"Mohon maaf, saya belum mendeteksi game spesifik dari query Anda. Apakah ada game tertentu yang ingin Anda mainkan di laptop baru Anda?\"]})\n",
        "        else:\n",
        "             # Jika tidak ada info game, laptop, atau budget, query terlalu umum\n",
        "             print(\"Query terlalu umum.\")\n",
        "             # Fallback ke semantic search untuk game jika query tidak terlalu pendek dan relevan\n",
        "             query_tokens_cleaned = basic_preprocessing(user_query)\n",
        "             query_tokens_cleaned = remove_stopwords(query_tokens_cleaned)\n",
        "             query_tokens_cleaned = map_synonyms(query_tokens_cleaned)\n",
        "\n",
        "             if len(query_tokens_cleaned) > 1: # Jika masih ada token relevan setelah preprocessing\n",
        "                  print(\"Melakukan Semantic Search untuk game berdasarkan query umum...\")\n",
        "                  semantic_results = search_games(user_query, model, description_embeddings, min_req_df, top_n=top_n_semantic_games, category_boost=category_boost_value)\n",
        "                  game_targets = [res['game'] for res in semantic_results if res['similarity'] > 0.1] # Ambil game dengan similarity > threshold\n",
        "                  if game_targets:\n",
        "                       print(f\"Menemukan game relevan dari Semantic Search: {game_targets}\")\n",
        "\n",
        "                  else:\n",
        "                       print(\"Semantic Search tidak menemukan game relevan.\")\n",
        "                       return pd.DataFrame({\"Status\": [\"Tidak Ditemukan\"], \"Pesan\": [\"Tidak dapat menemukan game relevan dari query Anda.\"]})\n",
        "             else:\n",
        "                  print(\"Query terlalu pendek atau tidak relevan setelah preprocessing.\")\n",
        "                  return pd.DataFrame({\"Status\": [\"Tidak Ditemukan\"], \"Pesan\": [\"Query Anda terlalu umum atau tidak jelas. Mohon berikan nama game, brand/model laptop, atau budget yang spesifik.\"]})\n",
        "\n",
        "    if found_games:\n",
        "        game_targets = found_games\n",
        "        print(f\"Menggunakan game yang terdeteksi spesifik: {game_targets}\")\n",
        "\n",
        "    target_game_min_req = None\n",
        "    target_game_rec_req = None\n",
        "\n",
        "    if game_targets: # Pastikan game_targets tidak kosong setelah semua pengecekan/semantic search\n",
        "        first_game = game_targets[0] # Ambil game pertama sebagai target utama\n",
        "        target_game_min_req = min_req_kb.get(first_game)\n",
        "        target_game_rec_req = rec_req_kb.get(first_game)\n",
        "\n",
        "        if not target_game_min_req or not target_game_rec_req:\n",
        "            print(f\"Persyaratan game '{first_game}' tidak ditemukan di knowledge base.\")\n",
        "            # Fallback: coba game target berikutnya jika ada\n",
        "            for next_game in game_targets[1:]:\n",
        "                 target_game_min_req = min_req_kb.get(next_game)\n",
        "                 target_game_rec_req = rec_req_kb.get(next_game)\n",
        "                 if target_game_min_req and target_game_rec_req:\n",
        "                      first_game = next_game # Update game target utama\n",
        "                      print(f\"Menggunakan persyaratan game alternatif: {first_game}\")\n",
        "                      break # Gunakan game pertama yang persyaratannya ditemukan\n",
        "\n",
        "            if not target_game_min_req or not target_game_rec_req:\n",
        "                 print(\"Tidak dapat menemukan persyaratan yang valid untuk game target.\")\n",
        "                 return pd.DataFrame({\"Status\": [\"Tidak Ditemukan\"], \"Pesan\": [f\"Persyaratan untuk game '{first_game}' atau game relevan lainnya tidak ditemukan.\"]})\n",
        "\n",
        "        print(f\"Persyaratan Min: {target_game_min_req['CPU_Intel']} / {target_game_min_req['GPU_NVIDIA']}, RAM: {target_game_min_req['RAM']}, Storage: {target_game_min_req['File Size']}\")\n",
        "        print(f\"Persyaratan Rec: {target_game_rec_req['CPU_Intel']} / {target_game_rec_req['GPU_NVIDIA']}, RAM: {target_game_rec_req['RAM']}, Storage: {target_game_rec_req['File Size']}\")\n",
        "    else:\n",
        "         # Ini seharusnya sudah ditangani di blok if not found_games di atas,\n",
        "         # tapi sebagai fallback keamanan:\n",
        "         print(\"Tidak ada game relevan yang ditemukan dari query setelah semua upaya.\")\n",
        "         return pd.DataFrame({\"Status\": [\"Tidak Ditemukan\"], \"Pesan\": [\"Tidak dapat menemukan game relevan dari query Anda.\"]})\n",
        "\n",
        "\n",
        "    # 3. Siapkan Daftar Laptop untuk Dievaluasi (Filter Budget, Brand, Model)\n",
        "    laptops_to_evaluate = laptop_df.copy()\n",
        "\n",
        "    # Filter Budget\n",
        "    if extracted_budget is not None and extracted_budget > 0:\n",
        "        print(f\"Memfilter laptop dengan budget <= {extracted_budget}\")\n",
        "        laptops_to_evaluate = laptops_to_evaluate[laptops_to_evaluate['Final Price'] <= extracted_budget].copy()\n",
        "        print(f\"Jumlah laptop setelah filter budget: {len(laptops_to_evaluate)}\") # Debug print: Jumlah laptop setelah filter budget\n",
        "        if laptops_to_evaluate.empty:\n",
        "            print(\"Tidak ada laptop dalam budget yang terdeteksi.\")\n",
        "            return pd.DataFrame({\"Status\": [\"Tidak Ditemukan\"], \"Pesan\": [f\"Tidak ada laptop dalam budget {extracted_budget:,} yang tersedia.\"]})\n",
        "\n",
        "    # Filter Brand atau Model Spesifik\n",
        "    if found_laptops_entities:\n",
        "        print(f\"Memfilter laptop berdasarkan entitas: {found_laptops_entities}\")\n",
        "        filter_mask = pd.Series([False] * len(laptops_to_evaluate), index=laptops_to_evaluate.index)\n",
        "        for entity in found_laptops_entities:\n",
        "            if entity in laptop_brand_list:\n",
        "                filter_mask |= (laptops_to_evaluate['Brand'].str.lower() == entity.lower())\n",
        "            elif entity in laptop_list:\n",
        "                 filter_mask |= (laptops_to_evaluate['Model'].str.lower() == entity.lower())\n",
        "            else:\n",
        "                 brand_match = process.extractOne(entity, laptops_to_evaluate['Brand'].tolist(), score_cutoff=90)\n",
        "                 model_match = process.extractOne(entity, laptops_to_evaluate['Model'].tolist(), score_cutoff=90)\n",
        "                 if brand_match and brand_match[1] >= 90:\n",
        "                      filter_mask |= (laptops_to_evaluate['Brand'].str.lower() == brand_match[0].lower())\n",
        "                 if model_match and model_match[1] >= 90:\n",
        "                      filter_mask |= (laptops_to_evaluate['Model'].str.lower() == model_match[0].lower())\n",
        "\n",
        "        laptops_to_evaluate = laptops_to_evaluate[filter_mask].copy()\n",
        "        print(f\"Jumlah laptop setelah filter entitas: {len(laptops_to_evaluate)}\") # Debug print: Jumlah laptop setelah filter entitas\n",
        "\n",
        "        if laptops_to_evaluate.empty:\n",
        "            print(f\"Tidak ada laptop yang cocok dengan entitas '{', '.join(found_laptops_entities)}' dalam budget yang terdeteksi.\")\n",
        "            return pd.DataFrame({\"Status\": [\"Tidak Ditemukan\"], \"Pesan\": [f\"Tidak ada laptop yang cocok dengan '{', '.join(found_laptops_entities)}' dalam kriteria Anda.\"]})\n",
        "\n",
        "\n",
        "    # 4. Kategorisasi Laptop (Menggunakan categorize_laptops)\n",
        "    def categorize_laptops_adapted(df_laptops_filtered, req_row_min, req_row_rec, ram_weight=1.0, storage_weight=1.0):\n",
        "        if df_laptops_filtered.empty:\n",
        "             return pd.DataFrame()\n",
        "\n",
        "        ram_req = req_row_min['RAM']\n",
        "        storage_req = req_row_min['File Size']\n",
        "\n",
        "        def get_gpu_vendor(gpu_name):\n",
        "            if pd.isna(gpu_name): return 'intel'\n",
        "            gpu_name = str(gpu_name).lower()\n",
        "            if any(x in gpu_name for x in ['rtx', 'gtx', 'mx']): return 'nvidia'\n",
        "            elif any(x in gpu_name for x in ['radeon', 'rx', 'vega', 'pro']): return 'amd'\n",
        "            elif any(x in gpu_name for x in ['integrated', 'iris', 'uhd', 'hd graphics']): return 'intel'\n",
        "            else: return 'intel'\n",
        "\n",
        "        def get_cpu_vendor(cpu_name):\n",
        "            if pd.isna(cpu_name): return 'intel'\n",
        "            cpu_name = str(cpu_name).lower()\n",
        "            if 'intel' in cpu_name or any(x in cpu_name for x in ['core', 'pentium', 'celeron', 'xeon', 'evo']): return 'intel'\n",
        "            elif 'amd' in cpu_name or any(x in cpu_name for x in ['ryzen', 'fx', 'athlon', 'phenom', 'opteron']): return 'amd'\n",
        "            else: return 'intel'\n",
        "\n",
        "        def get_cpu_req_score(row, req_row):\n",
        "            vendor = get_cpu_vendor(row['CPU'])\n",
        "            if vendor == 'intel': return req_row['CPU_Intel_score']\n",
        "            elif vendor == 'amd': return req_row['CPU_AMD_score']\n",
        "            else: return req_row['CPU_Intel_score']\n",
        "\n",
        "        def get_gpu_req_score(row, req_row):\n",
        "            vendor = get_gpu_vendor(row['GPU'])\n",
        "            if vendor == 'nvidia': return req_row['GPU_NVIDIA_score']\n",
        "            elif vendor == 'amd': return req_row['GPU_AMD_score']\n",
        "            elif vendor == 'intel': return req_row['GPU_Intel_score']\n",
        "            else: return req_row['GPU_Intel_score']\n",
        "\n",
        "        def calculate_match(row):\n",
        "            cpu_req = get_cpu_req_score(row, req_row_rec)\n",
        "            gpu_req = get_gpu_req_score(row, req_row_rec)\n",
        "\n",
        "            cpu_score_ratio = row['CPU_score'] / cpu_req if cpu_req > 0 else 1.0\n",
        "            gpu_score_ratio = row['GPU_score'] / gpu_req if gpu_req > 0 else 1.0\n",
        "            ram_score_ratio = (row['RAM'] / ram_req) * ram_weight if ram_req > 0 else 1.0\n",
        "            storage_score_ratio = (row['Storage'] / storage_req) * storage_weight if storage_req > 0 else 1.0\n",
        "\n",
        "            cpu_score_ratio = min(cpu_score_ratio, 5.0)\n",
        "            gpu_score_ratio = min(gpu_score_ratio, 5.0)\n",
        "            ram_score_ratio = min(ram_score_ratio, 5.0)\n",
        "            storage_score_ratio = min(storage_score_ratio, 5.0)\n",
        "\n",
        "            final_score = (cpu_score_ratio + gpu_score_ratio + ram_score_ratio + storage_score_ratio) / (2 + ram_weight + storage_weight)\n",
        "            return final_score\n",
        "\n",
        "        def categorize(row):\n",
        "            cpu_min = get_cpu_req_score(row, req_row_min)\n",
        "            gpu_min = get_gpu_req_score(row, req_row_min)\n",
        "            cpu_rec = get_cpu_req_score(row, req_row_rec)\n",
        "            gpu_rec = get_gpu_req_score(row, req_row_rec)\n",
        "\n",
        "            # Check minimum requirements first\n",
        "            if row['CPU_score'] < cpu_min or row['GPU_score'] < gpu_min or row['RAM'] < ram_req or row['Storage'] < storage_req:\n",
        "                 return 'Disqualified'\n",
        "\n",
        "            cpu_rec_flag = row['CPU_score'] >= cpu_rec\n",
        "            gpu_rec_flag = row['GPU_score'] >= gpu_rec\n",
        "\n",
        "            if cpu_rec_flag and gpu_rec_flag: return 'Recommended'\n",
        "            elif cpu_rec_flag or gpu_rec_flag: return 'Mixed'\n",
        "            else: return 'Minimum'\n",
        "\n",
        "        df_filtered_req = df_laptops_filtered[\n",
        "            (df_laptops_filtered['RAM'] >= ram_req) & (df_laptops_filtered['Storage'] >= storage_req)\n",
        "        ].copy()\n",
        "        print(f\"Jumlah laptop setelah filter RAM/Storage minimum: {len(df_filtered_req)}\") # Debug print: Jumlah laptop setelah filter RAM/Storage\n",
        "\n",
        "        if df_filtered_req.empty:\n",
        "             print(\"Tidak ada laptop yang memenuhi persyaratan RAM dan Storage minimum.\")\n",
        "             return pd.DataFrame()\n",
        "\n",
        "        df_filtered_req['Match_Score'] = df_filtered_req.apply(calculate_match, axis=1)\n",
        "        df_filtered_req['Category'] = df_filtered_req.apply(categorize, axis=1)\n",
        "\n",
        "        df_final = df_filtered_req[df_filtered_req['Category'] != 'Disqualified'].copy()\n",
        "        df_final = df_final.sort_values(by='Match_Score', ascending=False).reset_index(drop=True)\n",
        "        return df_final[['Brand', 'Model', 'CPU', 'GPU', 'RAM', 'Storage', 'Final Price', 'Category', 'Match_Score']]\n",
        "\n",
        "\n",
        "    print(\"Mengkategorikan laptop...\")\n",
        "    final_recommendations = categorize_laptops_adapted(\n",
        "        laptops_to_evaluate,\n",
        "        target_game_min_req,\n",
        "        target_game_rec_req\n",
        "    )\n",
        "\n",
        "    # 5. Tampilkan Hasil\n",
        "    if final_recommendations.empty:\n",
        "        print(\"\\nTidak ada rekomendasi laptop yang ditemukan berdasarkan kriteria Anda.\")\n",
        "        print(\"Tidak ada laptop yang memenuhi persyaratan minimum game yang relevan di antara laptop yang sudah difilter.\")\n",
        "        return pd.DataFrame({\"Status\": [\"Tidak Ditemukan\"], \"Pesan\": [\"Tidak ada rekomendasi laptop yang memenuhi persyaratan minimum game yang relevan dalam kriteria Anda.\"]})\n",
        "    else:\n",
        "        print(\"\\nHasil Rekomendasi Laptop:\")\n",
        "        final_recommendations['Category_Order'] = final_recommendations['Category'].apply(\n",
        "            lambda x: 0 if x == 'Recommended' else (1 if x == 'Mixed' else 2)\n",
        "        )\n",
        "        final_recommendations = final_recommendations.sort_values(by=['Category_Order', 'Match_Score'], ascending=[True, False]).drop(columns='Category_Order')\n",
        "        display(final_recommendations)\n",
        "        return final_recommendations\n",
        "\n",
        "\n",
        "# --- Jalankan ulang query yang bermasalah dengan debug prints ---\n",
        "query_problem = \"Laptop yang cocok buat main valorant dengan laptop Asus dengan harga 100 juta\"\n",
        "recommendations_debug = get_laptop_recommendations(\n",
        "    query_problem, laptop_df, min_req_df, rec_req_df,\n",
        "    min_req_kb, rec_req_kb,\n",
        "    model, description_embeddings,\n",
        "    laptop_df['Model'].tolist(), laptop_df['Brand'].unique().tolist(), unique_keyword_game_map\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}